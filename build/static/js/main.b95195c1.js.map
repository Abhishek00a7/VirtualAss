{"version":3,"file":"static/js/main.b95195c1.js","mappings":";kvkBASgB,m+BATH,2CAWSA,mBAAmB,CACrCC,MAAO","sources":["index.js"],"sourcesContent":["let apikey = \"AIzaSyDGL6vXgJGKtqo4_oS2J8h1nKa_KD6fYg8\";\r\n\r\nimport {\r\n    GoogleGenerativeAI,\r\n    HarmCategory,\r\n    HarmBlockThreshold,\r\n  } from \"@google/generative-ai\";\r\n  \r\n \r\n  const genAI = new GoogleGenerativeAI(apikey);\r\n  \r\n  const model = genAI.getGenerativeModel({\r\n    model: \"gemini-2.0-flash\",\r\n  });\r\n  \r\n  const generationConfig = {\r\n    temperature: 1,\r\n    topP: 0.95,\r\n    topK: 40,\r\n    maxOutputTokens: 60,\r\n    responseMimeType: \"text/plain\",\r\n  };\r\n  \r\n  async function run(prompt) {\r\n    const chatSession = model.startChat({\r\n      generationConfig,\r\n      history: [\r\n      ],\r\n    });\r\n  \r\n    const result = await chatSession.sendMessage(prompt);\r\n    return result.response.text();\r\n  }\r\n  \r\n export default run;"],"names":["getGenerativeModel","model"],"sourceRoot":""}